{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyGX4hRSHU1d"
      },
      "source": [
        "# Overview\n",
        "\n",
        "This Colab helps to create a training set for the k-NN classifier described in the MediaPipe [Pose Classification](https://google.github.io/mediapipe/solutions/pose_classification.html) soultion, export it to a CSV and then use it in the [ML Kit sample app](https://developers.google.com/ml-kit/vision/pose-detection/classifying-poses#4_integrate_with_the_ml_kit_quickstart_app)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DpCfLGxsdzg"
      },
      "source": [
        "# Step 0: Start Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKqTTP3XsekH"
      },
      "source": [
        "Connect the Colab to hosted Python3 runtime (check top-right corner) and then install required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpZrq2Ktsgdu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0d715b3-0b19-4747-a1fe-33f021dbe956"
      },
      "source": [
        "!pip install numpy==1.19.3\n",
        "!pip install opencv-python==4.5.1.48\n",
        "!pip install tqdm==4.56.0\n",
        "\n",
        "!pip install mediapipe==0.8.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.19.3\n",
            "  Downloading numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 2.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.3 which is incompatible.\n",
            "tensorflow 2.9.2 requires numpy>=1.20, but you have numpy 1.19.3 which is incompatible.\n",
            "jaxlib 0.3.22+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.3 which is incompatible.\n",
            "jax 0.3.23 requires numpy>=1.20, but you have numpy 1.19.3 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.19.3 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python==4.5.1.48\n",
            "  Downloading opencv_python-4.5.1.48-cp37-cp37m-manylinux2014_x86_64.whl (50.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 50.4 MB 75 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.5.1.48) (1.19.3)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.6.0.66\n",
            "    Uninstalling opencv-python-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-4.6.0.66\n",
            "Successfully installed opencv-python-4.5.1.48\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tqdm==4.56.0\n",
            "  Downloading tqdm-4.56.0-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 905 kB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.19.3 which is incompatible.\u001b[0m\n",
            "Successfully installed tqdm-4.56.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe==0.8.3\n",
            "  Downloading mediapipe-0.8.3-cp37-cp37m-manylinux2014_x86_64.whl (67.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 67.0 MB 95 kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe==0.8.3) (3.19.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mediapipe==0.8.3) (1.15.0)\n",
            "Requirement already satisfied: numpy==1.19.3 in /usr/local/lib/python3.7/dist-packages (from mediapipe==0.8.3) (1.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from mediapipe==0.8.3) (4.5.1.48)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from mediapipe==0.8.3) (22.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from mediapipe==0.8.3) (0.38.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe==0.8.3) (1.3.0)\n",
            "Installing collected packages: dataclasses, mediapipe\n",
            "Successfully installed dataclasses-0.6 mediapipe-0.8.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgHTsKdz7cn_"
      },
      "source": [
        "# Step 1: Upload image samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BfvGuy37ih1"
      },
      "source": [
        "Locally create a folder named `fitness_poses_images_in` with image samples.\n",
        "\n",
        "Images should repesent terminal states of desired pose classes. I.e. if you want to classify push-up provide iamges for two classes: when person is up, and when person is down.\n",
        "\n",
        "There should be about a few hundred samples per class covering different camera angles, environment conditions, body shapes, and exercise variations to build a good classifier.\n",
        "\n",
        "Required structure of the images_in_folder:\n",
        "```\n",
        "fitness_poses_images_in/\n",
        "  pushups_up/\n",
        "    image_001.jpg\n",
        "    image_002.jpg\n",
        "    ...\n",
        "  pushups_down/\n",
        "    image_001.jpg\n",
        "    image_002.jpg\n",
        "    ...\n",
        "  ...\n",
        "```\n",
        "\n",
        "Zip the `fitness_poses_images_in` folder:\n",
        "```\n",
        "zip -r fitness_poses_images_in.zip fitness_poses_images_in\n",
        "```\n",
        "\n",
        "And run the code below to upload it to the Colab runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJHy8QbK7f9Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "fafc13e7-40de-4e54-8580-f7418ee4cbf6"
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "os.listdir('.')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e5ac1eac-6819-4a5a-93a8-9b61eaed4421\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e5ac1eac-6819-4a5a-93a8-9b61eaed4421\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving submit.zip to submit.zip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'poses_csvs_out',\n",
              " 'poses_csvs_out.csv',\n",
              " 'poses_image_out_basic',\n",
              " 'poses_image_out',\n",
              " '.ipynb_checkpoints',\n",
              " 'submit.zip',\n",
              " 'poses_image_in',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MUhn--d82Mv"
      },
      "source": [
        "Unzip the archive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PvT2NOt863S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "424f8f9f-5c62-41bf-e70f-5a15946f3ffa"
      },
      "source": [
        "import zipfile\n",
        "import io\n",
        "\n",
        "zf = zipfile.ZipFile(io.BytesIO(uploaded['submit.zip']), \"r\")\n",
        "zf.extractall()\n",
        "os.listdir('.')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'poses_csvs_out',\n",
              " 'poses_csvs_out.csv',\n",
              " 'poses_image_out_basic',\n",
              " 'poses_image_out',\n",
              " '.ipynb_checkpoints',\n",
              " 'submit.zip',\n",
              " 'poses_image_in',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdtsJ8TvqktY"
      },
      "source": [
        "# Step 2: Create samples for classifier\n",
        "\n",
        "Runs BlazePose on provided images to get target poses for the classifier in a format required by the demo App."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PiV3r_Pphln"
      },
      "source": [
        "# Folder with images to use as target poses for classification.\n",
        "#\n",
        "# Images should repesent terminal states of desired pose classes. I.e. if you\n",
        "# want to classify push-up provide iamges for two classes: when person is up,\n",
        "# and when person is down.\n",
        "#\n",
        "# Required structure of the images_in_folder:\n",
        "#   fitness_poses_images_in/\n",
        "#     pushups_up/\n",
        "#       image_001.jpg\n",
        "#       image_002.jpg\n",
        "#       ...\n",
        "#     pushups_down/\n",
        "#       image_001.jpg\n",
        "#       image_002.jpg\n",
        "#       ...\n",
        "#     ...\n",
        "images_in_folder = 'poses_image_in'\n",
        "\n",
        "# Output folders for bootstrapped images and CSVs. Image will have a predicted\n",
        "# Pose rendering and can be used to remove unwanted samples.\n",
        "images_out_folder = 'poses_image_out'\n",
        "\n",
        "# Output CSV path to put bootstrapped poses to. This CSV will be used by the\n",
        "# demo App.\n",
        "#\n",
        "# Output CSV format:\n",
        "#   sample_00001,pose_class_1,x1,y1,z1,x2,y2,z2,...,x33,y33,z33\n",
        "#   sample_00002,pose_class_2,x1,y1,z1,x2,y2,z2,...,x33,y33,z33\n",
        "#   ...\n",
        "#\n",
        "csv_out_path = 'poses_csvs_out.csv'"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.exists(os.path.join(images_out_folder, 'pose_class_name'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqfWIjNs67W3",
        "outputId": "d3f07cd0-5828-4074-9ee8-15748293c99f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btboitEDrSDq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "26fb06e4-7d88-409d-ea83-64245b21f5df"
      },
      "source": [
        "import csv\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tqdm\n",
        "\n",
        "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
        "from mediapipe.python.solutions import pose as mp_pose\n",
        "\n",
        "\n",
        "with open(csv_out_path, 'w') as csv_out_file:\n",
        "  csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
        "\n",
        "  # Folder names are used as pose class names.\n",
        "  pose_class_names = sorted([n for n in os.listdir(images_in_folder) if not n.startswith('.')])\n",
        "\n",
        "  for pose_class_name in pose_class_names:\n",
        "    print('Bootstrapping ', pose_class_name, file=sys.stderr)\n",
        "\n",
        "    if not os.path.exists(os.path.join(images_out_folder, pose_class_name)):\n",
        "      os.makedirs(os.path.join(images_out_folder, pose_class_name))\n",
        "\n",
        "    image_names = sorted([\n",
        "        n for n in os.listdir(os.path.join(images_in_folder, pose_class_name))\n",
        "        if not n.startswith('.')])\n",
        "\n",
        "    for image_name in tqdm.tqdm(image_names, position=0):\n",
        "      # Load image.\n",
        "      input_frame = cv2.imread(os.path.join(images_in_folder, pose_class_name, image_name))\n",
        "      input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      # Initialize fresh pose tracker and run it.\n",
        "      with mp_pose.Pose(upper_body_only=False) as pose_tracker:\n",
        "        result = pose_tracker.process(image=input_frame)\n",
        "        pose_landmarks = result.pose_landmarks\n",
        "      \n",
        "      # Save image with pose prediction (if pose was detected).\n",
        "      output_frame = input_frame.copy()\n",
        "      if pose_landmarks is not None:\n",
        "        mp_drawing.draw_landmarks(\n",
        "            image=output_frame,\n",
        "            landmark_list=pose_landmarks,\n",
        "            connections=mp_pose.POSE_CONNECTIONS)\n",
        "      output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
        "      cv2.imwrite(os.path.join(images_out_folder, image_name), output_frame)\n",
        "      \n",
        "      # Save landmarks.\n",
        "      if pose_landmarks is not None:\n",
        "        # Check the number of landmarks and take pose landmarks.\n",
        "        assert len(pose_landmarks.landmark) == 33, 'Unexpected number of predicted pose landmarks: {}'.format(len(pose_landmarks.landmark))\n",
        "        pose_landmarks = [[lmk.x, lmk.y, lmk.z] for lmk in pose_landmarks.landmark]\n",
        "\n",
        "        # Map pose landmarks from [0, 1] range to absolute coordinates to get\n",
        "        # correct aspect ratio.\n",
        "        frame_height, frame_width = output_frame.shape[:2]\n",
        "        pose_landmarks *= np.array([frame_width, frame_height, frame_width])\n",
        "\n",
        "        # Write pose sample to CSV.\n",
        "        pose_landmarks = np.around(pose_landmarks, 5).flatten().astype(np.str).tolist()\n",
        "        csv_out_writer.writerow([image_name, pose_class_name] + pose_landmarks)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bootstrapping  11-0.png\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-327d6b287a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     image_names = sorted([\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_in_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose_class_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         if not n.startswith('.')])\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: 'poses_image_in/11-0.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfD86A2d1-8j"
      },
      "source": [
        "Now look at the output images with predicted Pose and remove those you are not satisfied with from the output CSV. Wrongly predicted poses will affect accuracy of the classification.\n",
        "\n",
        "Once done, you can use the CSV in the demo App.\n",
        "\n",
        "For more accurate validation of the predicted Poses use extended Colab provided in the documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIMSXunH9g6P"
      },
      "source": [
        "# Step 3: Download CSV\n",
        "\n",
        "Please check this [guide](https://developers.google.com/ml-kit/vision/pose-detection/classifying-poses#4_integrate_with_the_ml_kit_quickstart_app) on how to use this CSV in the ML Kit sample app."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90E4HOoJ9uMY"
      },
      "source": [
        "files.download(csv_out_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
